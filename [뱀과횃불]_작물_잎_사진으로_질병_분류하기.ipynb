{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/freud-sensei/imfine_torch/blob/main/%5B%EB%B1%80%EA%B3%BC%ED%9A%83%EB%B6%88%5D_%EC%9E%91%EB%AC%BC_%EC%9E%8E_%EC%82%AC%EC%A7%84%EC%9C%BC%EB%A1%9C_%EC%A7%88%EB%B3%91_%EB%B6%84%EB%A5%98%ED%95%98%EA%B8%B0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 실험 설계를 위한 데이터 분할"
      ],
      "metadata": {
        "id": "96hzS7l6090X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fwWLB7gnGSwH",
        "outputId": "29db8e71-1105-44f4-98b9-6507879fa6c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.chdir('/content/drive/MyDrive')"
      ],
      "metadata": {
        "id": "n6nBoUHIXgaQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -qq './dataset.zip' -d './dataset'"
      ],
      "metadata": {
        "id": "HqhgPDisFxhJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 데이터 분할을 위한 폴더 생성"
      ],
      "metadata": {
        "id": "_jj0E4CJ15-t"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C7-Wh1ZrxmcG"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "original_dataset_dir = './dataset'\n",
        "classes_list = os.listdir(original_dataset_dir) # 경로 하위에 있는 모든 폴더의 목록을 가져온다\n",
        "base_dir = './splitted' # 나눈 데이터를 저장할 폴더\n",
        "os.mkdir(base_dir)\n",
        "\n",
        "# train, valid, test 폴더를 만드는 과정\n",
        "train_dir = os.path.join(base_dir, 'train')\n",
        "os.mkdir(train_dir)\n",
        "validation_dir = os.path.join(base_dir, 'val')\n",
        "os.mkdir(validation_dir)\n",
        "test_dir = os.path.join(base_dir, 'test')\n",
        "os.mkdir(test_dir)\n",
        "\n",
        "# train, valid, test 폴더 아래에 각 클래스별 폴더 생성\n",
        "for clss in classes_list:\n",
        "  os.mkdir(os.path.join(train_dir, clss))\n",
        "  os.mkdir(os.path.join(validation_dir, clss))\n",
        "  os.mkdir(os.path.join(test_dir, clss))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 데이터 분할과 클래스별 데이터 수 확인"
      ],
      "metadata": {
        "id": "FNLFGrKZ4iFH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "\n",
        "for clss in classes_list:\n",
        "  # train, validation, test dataset으로 분\n",
        "  path = os.path.join(original_dataset_dir, clss) # 예: 'leaf_dataset/Apple__Apple_scab'\n",
        "  fnames = os.listdir(path) # 각 class 폴더별 이미지의 리스트. 그 수를 확인할 수 있겠지\n",
        "  train_size = math.floor(len(fnames) * 0.6)\n",
        "  validation_size = math.floor(len(fnames) * 0.2)\n",
        "  test_size = math.floor(len(fnames) * 0.2)\n",
        "\n",
        "  # 원래 폴더에서 각 클래스별 폴더로 이동\n",
        "  train_fnames = fnames[:train_size]\n",
        "  print('Train size(', clss, '): ', len(train_fnames))\n",
        "  for fname in train_fnames:\n",
        "    source = os.path.join(path, fname) # 예: 'leaf_dataset/Apple__Apple_scab/image (1).JPG'\n",
        "    dest = os.path.join(os.path.join(train_dir, clss), fname) # 예: 'splitted/train/Apple_Apple_scab/image (1).JPG'\n",
        "    shutil.copyfile(source, dest)\n",
        "\n",
        "  validation_fnames = fnames[train_size:(validation_size + train_size)]\n",
        "  print('Validation size(', clss, '): ', len(validation_fnames))\n",
        "  for fname in validation_fnames:\n",
        "    source = os.path.join(path, fname)\n",
        "    dest = os.path.join(os.path.join(validation_dir, clss), fname)\n",
        "    shutil.copyfile(source, dest)\n",
        "\n",
        "  test_fnames = fnames[(train_size + validation_size):(validation_size + train_size + test_size)]\n",
        "  print('Test size(', clss, '): ', len(test_fnames))\n",
        "  for fname in test_fnames:\n",
        "    source = os.path.join(path, fname)\n",
        "    dest = os.path.join(os.path.join(test_dir, clss), fname)\n",
        "    shutil.copyfile(source, dest)"
      ],
      "metadata": {
        "id": "nGAS7jAT4lC4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "27073754-a3af-4190-80bb-0f3051a94486"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train size( Pepper,_bell___healthy ):  886\n",
            "Validation size( Pepper,_bell___healthy ):  295\n",
            "Test size( Pepper,_bell___healthy ):  295\n",
            "Train size( Grape___Esca_(Black_Measles) ):  829\n",
            "Validation size( Grape___Esca_(Black_Measles) ):  276\n",
            "Test size( Grape___Esca_(Black_Measles) ):  276\n",
            "Train size( Pepper,_bell___Bacterial_spot ):  598\n",
            "Validation size( Pepper,_bell___Bacterial_spot ):  199\n",
            "Test size( Pepper,_bell___Bacterial_spot ):  199\n",
            "Train size( Strawberry___healthy ):  273\n",
            "Validation size( Strawberry___healthy ):  91\n",
            "Test size( Strawberry___healthy ):  91\n",
            "Train size( Grape___Black_rot ):  708\n",
            "Validation size( Grape___Black_rot ):  236\n",
            "Test size( Grape___Black_rot ):  236\n",
            "Train size( Corn___Common_rust ):  715\n",
            "Validation size( Corn___Common_rust ):  238\n",
            "Test size( Corn___Common_rust ):  238\n",
            "Train size( Apple___Apple_scab ):  378\n",
            "Validation size( Apple___Apple_scab ):  126\n",
            "Test size( Apple___Apple_scab ):  126\n",
            "Train size( Potato___healthy ):  91\n",
            "Validation size( Potato___healthy ):  30\n",
            "Test size( Potato___healthy ):  30\n",
            "Train size( Potato___Late_blight ):  600\n",
            "Validation size( Potato___Late_blight ):  200\n",
            "Test size( Potato___Late_blight ):  200\n",
            "Train size( Cherry___healthy ):  512\n",
            "Validation size( Cherry___healthy ):  170\n",
            "Test size( Cherry___healthy ):  170\n",
            "Train size( Tomato___Bacterial_spot ):  1276\n",
            "Validation size( Tomato___Bacterial_spot ):  425\n",
            "Test size( Tomato___Bacterial_spot ):  425\n",
            "Train size( Apple___Black_rot ):  372\n",
            "Validation size( Apple___Black_rot ):  124\n",
            "Test size( Apple___Black_rot ):  124\n",
            "Train size( Cherry___Powdery_mildew ):  631\n",
            "Validation size( Cherry___Powdery_mildew ):  210\n",
            "Test size( Cherry___Powdery_mildew ):  210\n",
            "Train size( Corn___Cercospora_leaf_spot Gray_leaf_spot ):  307\n",
            "Validation size( Corn___Cercospora_leaf_spot Gray_leaf_spot ):  102\n",
            "Test size( Corn___Cercospora_leaf_spot Gray_leaf_spot ):  102\n",
            "Train size( Peach___healthy ):  216\n",
            "Validation size( Peach___healthy ):  72\n",
            "Test size( Peach___healthy ):  72\n",
            "Train size( Tomato___Early_blight ):  600\n",
            "Validation size( Tomato___Early_blight ):  200\n",
            "Test size( Tomato___Early_blight ):  200\n",
            "Train size( Tomato___Tomato_Yellow_Leaf_Curl_Virus ):  3214\n",
            "Validation size( Tomato___Tomato_Yellow_Leaf_Curl_Virus ):  1071\n",
            "Test size( Tomato___Tomato_Yellow_Leaf_Curl_Virus ):  1071\n",
            "Train size( Grape___Leaf_blight_(Isariopsis_Leaf_Spot) ):  645\n",
            "Validation size( Grape___Leaf_blight_(Isariopsis_Leaf_Spot) ):  215\n",
            "Test size( Grape___Leaf_blight_(Isariopsis_Leaf_Spot) ):  215\n",
            "Train size( Potato___Early_blight ):  600\n",
            "Validation size( Potato___Early_blight ):  200\n",
            "Test size( Potato___Early_blight ):  200\n",
            "Train size( Grape___healthy ):  253\n",
            "Validation size( Grape___healthy ):  84\n",
            "Test size( Grape___healthy ):  84\n",
            "Train size( Apple___Cedar_apple_rust ):  165\n",
            "Validation size( Apple___Cedar_apple_rust ):  55\n",
            "Test size( Apple___Cedar_apple_rust ):  55\n",
            "Train size( Corn___Northern_Leaf_Blight ):  591\n",
            "Validation size( Corn___Northern_Leaf_Blight ):  197\n",
            "Test size( Corn___Northern_Leaf_Blight ):  197\n",
            "Train size( Tomato___Septoria_leaf_spot ):  1062\n",
            "Validation size( Tomato___Septoria_leaf_spot ):  354\n",
            "Test size( Tomato___Septoria_leaf_spot ):  354\n",
            "Train size( Corn___healthy ):  697\n",
            "Validation size( Corn___healthy ):  232\n",
            "Test size( Corn___healthy ):  232\n",
            "Train size( Strawberry___Leaf_scorch ):  665\n",
            "Validation size( Strawberry___Leaf_scorch ):  221\n",
            "Test size( Strawberry___Leaf_scorch ):  221\n",
            "Train size( Tomato___Tomato_mosaic_virus ):  223\n",
            "Validation size( Tomato___Tomato_mosaic_virus ):  74\n",
            "Test size( Tomato___Tomato_mosaic_virus ):  74\n",
            "Train size( Tomato___Leaf_Mold ):  571\n",
            "Validation size( Tomato___Leaf_Mold ):  190\n",
            "Test size( Tomato___Leaf_Mold ):  190\n",
            "Train size( Tomato___Late_blight ):  1145\n",
            "Validation size( Tomato___Late_blight ):  381\n",
            "Test size( Tomato___Late_blight ):  381\n",
            "Train size( Tomato___healthy ):  954\n",
            "Validation size( Tomato___healthy ):  318\n",
            "Test size( Tomato___healthy ):  318\n",
            "Train size( Tomato___Spider_mites Two-spotted_spider_mite ):  1005\n",
            "Validation size( Tomato___Spider_mites Two-spotted_spider_mite ):  335\n",
            "Test size( Tomato___Spider_mites Two-spotted_spider_mite ):  335\n",
            "Train size( Apple___healthy ):  987\n",
            "Validation size( Apple___healthy ):  329\n",
            "Test size( Apple___healthy ):  329\n",
            "Train size( Tomato___Target_Spot ):  842\n",
            "Validation size( Tomato___Target_Spot ):  280\n",
            "Test size( Tomato___Target_Spot ):  280\n",
            "Train size( Peach___Bacterial_spot ):  1378\n",
            "Validation size( Peach___Bacterial_spot ):  459\n",
            "Test size( Peach___Bacterial_spot ):  459\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 베이스라인 모델 학습을 위한 준비"
      ],
      "metadata": {
        "id": "wcyKd6DF60oC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "use_cuda = torch.cuda.is_available()\n",
        "device = 'cuda' if use_cuda else 'cpu'\n",
        "batch_size = 256\n",
        "epoch = 1"
      ],
      "metadata": {
        "id": "gOpADiFA68Aj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1. Dataset, DataLoader 생성**"
      ],
      "metadata": {
        "id": "0pOpPJ8Y64X3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision.transforms as transforms\n",
        "from torchvision.datasets import ImageFolder # 데이터셋을 불러온다. 하나의 클래스가 하나의 폴더인 형태에 유용.\n",
        "\n",
        "transform_base = transforms.Compose([transforms.Resize((64, 64)),\n",
        "                                     transforms.ToTensor()])\n",
        "# 이미지의 크기를 (64, 64)로 조정하고, 이후 Tensor 형태로 변환 후 값을 0에서 1 사이로 normalize한다.\n",
        "train_dataset = ImageFolder(root='./splitted/train', transform=transform_base)\n",
        "val_dataset = ImageFolder(root='./splitted/val', transform=transform_base)\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True, num_workers=2)"
      ],
      "metadata": {
        "id": "6TA1KchU7KUI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = train_loader.__iter__().__next__()\n",
        "print(x[0].shape, x[1].shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zZH_JIThcwoW",
        "outputId": "0b0f745d-fbf4-4aed-8df0-91a625ef1816"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([256, 3, 64, 64]) torch.Size([256])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 베이스라인 모델 설계"
      ],
      "metadata": {
        "id": "Ii1Lerrx9HMO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. 모델 설계하기**\n",
        "\n",
        "**3. 옵티마이저와 손실함수 설정하기**"
      ],
      "metadata": {
        "id": "EahENEPL9JAy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "class Net(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=1)\n",
        "    self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "    self.dropout1 = nn.Dropout(p=0.25)\n",
        "    self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1)\n",
        "    self.dropout2 = nn.Dropout(p=0.25)\n",
        "    self.conv3 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, padding=1)\n",
        "    self.dropout3 = nn.Dropout(p=0.25)\n",
        "    self.fc1 = nn.Linear(4096, 512)\n",
        "    self.dropout4 = nn.Dropout(p=0.5)\n",
        "    self.fc2 = nn.Linear(512, 33)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.conv1(x)\n",
        "    x = F.relu(x)\n",
        "    x = self.pool(x)\n",
        "    x = self.dropout1(x)\n",
        "\n",
        "    x = self.conv2(x)\n",
        "    x = F.relu(x)\n",
        "    x = self.pool(x)\n",
        "    x = self.dropout2(x)\n",
        "\n",
        "    x = self.conv3(x)\n",
        "    x = F.relu(x)\n",
        "    x = self.pool(x)\n",
        "    x = self.dropout3(x)\n",
        "\n",
        "    x = x.view(-1, 4096) # (여기서 0번째 차원의 길이는 batch의 데이터 수가 된다.)\n",
        "    x = self.fc1(x)\n",
        "    x = F.relu(x)\n",
        "    x = self.dropout4(x)\n",
        "    x = self.fc2(x)\n",
        "\n",
        "    return F.log_softmax(x, dim=1)\n",
        "\n",
        "model_base = Net().to(device)\n",
        "optimizer = optim.Adam(model_base.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "r1UB-ekV9RpR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 모델 학습을 위한 함수"
      ],
      "metadata": {
        "id": "9NcppTAEBrps"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, train_loader, optimizer):\n",
        "  model.train()\n",
        "  for batch_idx, (data, target) in enumerate(train_loader):\n",
        "    data, target = data.to(device), target.to(device)\n",
        "    optimizer.zero_grad()\n",
        "    output = model(data)\n",
        "    loss = F.cross_entropy(output, target)\n",
        "    loss.backward()\n",
        "    optimizer.step()"
      ],
      "metadata": {
        "id": "7_V-J1-6Bv2y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 모델 평가를 위한 함수"
      ],
      "metadata": {
        "id": "FR8XvXetEAIw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, test_loader):\n",
        "  model.eval()\n",
        "  test_loss = 0\n",
        "  correct = 0\n",
        "\n",
        "  with torch.no_grad(): # parameter 업데이트 중단\n",
        "    for data, target in test_loader:\n",
        "      data, target = data.to(device), target.to(device)\n",
        "      output = model(data)\n",
        "      test_loss += F.cross_entropy(output, target, reduction='sum').item()\n",
        "      pred = output.max(1)[1]\n",
        "      correct += (pred == target).sum()\n",
        "\n",
        "  test_loss /= len(test_loader.dataset)\n",
        "  test_accuracy = 100. * correct / len(test_loader.dataset)\n",
        "  return test_loss, test_accuracy"
      ],
      "metadata": {
        "id": "jxTABleBGrPc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 학습 실행"
      ],
      "metadata": {
        "id": "i9h7qTBlZrVB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import copy\n",
        "\n",
        "def train_baseline(model, train_loader, val_loader, optimizer, num_epochs = 30):\n",
        "  best_acc = 0.0\n",
        "  best_model = copy.deepcopy(model.state_dict())\n",
        "  # state_dict 는 간단히 말해 각 계층을 매개변수 텐서로 매핑되는 Python 사전(dict) 객체입니다.\n",
        "\n",
        "  for epoch in range(num_epochs):\n",
        "    since = time.time()\n",
        "    train(model, train_loader, optimizer)\n",
        "    train_loss, train_acc = evaluate(model, train_loader) # 해당 epoch에서의 학습 loss, 정확도\n",
        "    val_loss, val_acc = evaluate(model, val_loader) # 해당 epoch에서의 검증 loss, 정확도\n",
        "    if val_acc > best_acc:\n",
        "      best_acc = val_acc\n",
        "      best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    time_elapsed = time.time() - since\n",
        "\n",
        "    print(f\"epoch {epoch}\")\n",
        "    print(f\"train loss: {train_loss:.4f}, accuracy: {train_acc:.2f}\")\n",
        "    print(f\"validation loss: {val_loss:.4f}, accuracy: {val_acc:.2f}\")\n",
        "    print(f\"completed in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s\")\n",
        "\n",
        "  model.load_state_dict(best_model_wts)\n",
        "  return model\n",
        "\n",
        "base = train_baseline(model_base, train_loader, val_loader, optimizer, 3)\n",
        "torch.save(base, 'baseline.pt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Verk1bcIZxHR",
        "outputId": "5220c415-4381-4b33-b7fd-d918749d44c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0\n",
            "train loss: 0.0475, accuracy: 98.91\n",
            "validation loss: 0.1961, accuracy: 93.78\n",
            "completed in 1m 55s\n",
            "epoch 1\n",
            "train loss: 0.0475, accuracy: 98.91\n",
            "validation loss: 0.1961, accuracy: 93.78\n",
            "completed in 1m 54s\n",
            "epoch 2\n",
            "train loss: 0.0475, accuracy: 98.91\n",
            "validation loss: 0.1961, accuracy: 93.78\n",
            "completed in 2m 2s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Transfer Learning"
      ],
      "metadata": {
        "id": "-cIPVgNCbcFO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 높은 성능의 이미지 분류 모델을 구축하기 위해선, 질 좋은 데이터셋이 필요하다. 하지만 이를 대량으로 구하기는 어려움\n",
        "* **Transfer Learning(전이학습)**: 대량의 데이터셋으로 학습된 모델(pre-trained model)을 재활용한 후, 일부를 조정(fine-tuning)하여 다른 주제의 이미지 분류 모델에 사용하는 것\n",
        "* `torchvision.models` 패키지의 모델을 사용 가능"
      ],
      "metadata": {
        "id": "n2wf4JUabwp9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**가중치 학습**\n",
        "* 처음부터 딥러닝 모델을 설계하고 학습을 진행할 땐, 초기 parameter 값이 random하게 설정된다.\n",
        "* transfer learning을 할 땐, 대량의 데이터로 학습된 parameter 값을 불러온 후 학습 과정에서 update하게 된다.\n",
        "\n",
        "**Fine-tuning은 일종의 가중치 갱신**\n",
        "* parameter 값 일부를 데이터셋의 특성에 맞게 다시 학습하여 parameter를 조정하는 것 (layer를 freeze)\n",
        "* pre-trained model의 일부 layer는 업데이트되지 않고, 일부 layer는 업데이트되게끔 함\n",
        "\n",
        "**Freeze할 Layer를 결정하는 방법**\n",
        "* 큰 데이터셋 + pre-trained model 데이터셋과 유사: 일부 레이어를 훈련시킨다. (유사도가 높아 일부만 update해도 높은 효과)\n",
        "* 큰 데이터셋 + pre-trained model 데이터셋과 상이: 모델 전체를 훈련시킨다.\n",
        "* 작은 데이터셋 + pre-trained model 데이터셋과 유사: Convolutional Base를 freeze한다.\n",
        "* 작은 데이터셋 + pre-trained model 데이터셋과 상이: 일부 레이어를 훈련시킨다. (전체를 훈련하면 과적합의 위험)"
      ],
      "metadata": {
        "id": "z8hiyQr8daU1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Transfer Learning을 위한 준비"
      ],
      "metadata": {
        "id": "kCrFBIrsf0yq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_transforms = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.Resize([64, 64]),\n",
        "        transforms.RandomHorizontalFlip(), # 무작위샘플을 좌우반전 (default p=.5)\n",
        "        transforms.RandomVerticalFlip(), # 무작위샘플을 상하반전 (default p=.5)\n",
        "        transforms.RandomCrop(52), # 일부를 랜덤하게 잘라내어 52*52 사이즈로 변경\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                             [0.229, 0.224, 0.225])\n",
        "        # RGB 채널 값에서 정규화를 적용할 평균값, 표준편차 값\n",
        "        # 정규화는 모델 최적화 및 local minimum 방지에 도움이 됨\n",
        "    ]),\n",
        "    'val': transforms.Compose([\n",
        "        transforms.Resize([64, 64]),\n",
        "        transforms.RandomCrop(52),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                             [0.229, 0.224, 0.225])\n",
        "    ])\n",
        "}\n",
        "\n",
        "data_dir = './splitted'\n",
        "image_datasets = {x: ImageFolder(root=os.path.join(data_dir, x), transform=data_transforms[x]) for x in ['train', 'val']}\n",
        "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], shuffle=True, batch_size=batch_size, num_workers=2) for x in ['train', 'val']}\n",
        "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
        "class_names = image_datasets['train'].classes"
      ],
      "metadata": {
        "id": "2e_GcjC2dYGz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import models\n",
        "resnet = models.resnet50(pretrained=True)\n",
        "num_features = resnet.fc.in_features # ResNet의 마지막 Layer의 입력 채널 수\n",
        "# 모형의 마지막 FCN 대신 출력채널의 수가 33개인 새로운 Layer를 추가해야\n",
        "\n",
        "resnet.fc = nn.Linear(num_features, 33) # 이것만 바꿔치기\n",
        "resnet = resnet.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(filter(lambda p: p.requires_grad, resnet.parameters()), lr=0.001)\n",
        "# 설정한 일부 layer의 parameter만을 업데이트\n",
        "# requires_grad가 True로 설정된 parameter만\n",
        "\n",
        "from torch.optim import lr_scheduler\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
        "# optimizer의 learning rate를 epoch에 따라 변경하는 역할\n",
        "# 7 epoch마다 0.1씩 곱해 lr을 감소시킨다\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vjdqSke5hv9r",
        "outputId": "b5ed7ca2-ca24-46f7-8042-def4668bd687"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n",
            "100%|██████████| 97.8M/97.8M [00:00<00:00, 159MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "본 transfer learning에서는 fully connected layer 앞부분의 parameter는 고정시키고, 뒷부분만 학습하도록 하자."
      ],
      "metadata": {
        "id": "-GdxKptHjmlu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "count = 0\n",
        "for child in resnet.children(): # 모델의 자식 모듈을 iterable로 반환하는 메서드\n",
        "  count += 1\n",
        "  if count < 6:\n",
        "    for param in child.parameters():\n",
        "      param.requires_grad = False\n",
        "      # 1~5번 layer의 parameter는 update X. 6~10번만."
      ],
      "metadata": {
        "id": "X37PFN_zjxDc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 모델 학습 및 검증"
      ],
      "metadata": {
        "id": "7LdikA1AkZji"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_resnet(model, criterion, optimizer, scheduler, num_epochs=10):\n",
        "  best_model = copy.deepcopy(model.state_dict())\n",
        "  best_acc = .0\n",
        "\n",
        "  for epoch in range(3):\n",
        "    print(f\"epoch {epoch + 1}\")\n",
        "    since = time.time()\n",
        "\n",
        "    for phase in ['train', 'val']:\n",
        "      if phase == 'train':\n",
        "        model.train()\n",
        "      else:\n",
        "        model.eval()\n",
        "      running_loss = .0\n",
        "      running_corrects = 0\n",
        "\n",
        "      for data, target in dataloaders[phase]:\n",
        "        data = data.to(device)\n",
        "        target = target.to(device)\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        with torch.set_grad_enabled(phase=='train'):\n",
        "          # phase가 train일 때만 gradient를 계산\n",
        "          outputs = model(data)\n",
        "          preds = torch.max(outputs, axis=1)[1]\n",
        "          loss = criterion(outputs, target)\n",
        "          if phase == 'train':\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        running_loss += loss.item() * data.size(0) # data.size(0)은 배치 사이즈, 모든 데이터 Loss를 합산하고자 함\n",
        "        running_corrects += torch.sum(preds == target)\n",
        "\n",
        "      if phase == 'train':\n",
        "        scheduler.step()\n",
        "        l_r = [x['lr'] for x in optimizer.param_groups]\n",
        "        # 각 epoch의 learning rate를 불러온다\n",
        "        print('learning rate: ', l_r)\n",
        "\n",
        "      epoch_loss = running_loss / dataset_sizes[phase]\n",
        "      epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
        "      print(f\"{phase} Loss: {epoch_loss:.4f} Accuracy: {epoch_acc:.4f}\")\n",
        "\n",
        "      if phase == 'val' and epoch_acc > best_acc:\n",
        "        best_acc = epoch_acc\n",
        "        best_model = copy.deepcopy(model.state_dict())\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print(f\"completed in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s\")\n",
        "\n",
        "  print(f\"Best val acc: {best_acc:.4f}\")\n",
        "  model.load_state_dict(best_model)\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "uqdIEcLHke-p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_resnet50 = train_resnet(resnet, criterion, optimizer,\n",
        "                              exp_lr_scheduler, num_epochs=epoch)\n",
        "torch.save(model_resnet50, 'resnet50.pt')\n",
        "\n",
        "# 아마 훨씬 빠를 겁니다. 그러길 바랍니다."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5et44rELn5Xs",
        "outputId": "3b4ec6fa-8e55-4b61-a972-e5d46b2f160e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 1\n",
            "learning rate:  [0.001]\n",
            "train Loss: 0.2390 Accuracy: 0.9223\n",
            "val Loss: 0.2135 Accuracy: 0.9389\n",
            "completed in 1m 21s\n",
            "epoch 2\n",
            "learning rate:  [0.001]\n",
            "train Loss: 0.1686 Accuracy: 0.9443\n",
            "val Loss: 0.1561 Accuracy: 0.9483\n",
            "completed in 1m 21s\n",
            "epoch 3\n",
            "learning rate:  [0.001]\n",
            "train Loss: 0.1213 Accuracy: 0.9601\n",
            "val Loss: 0.1326 Accuracy: 0.9562\n",
            "completed in 1m 20s\n",
            "Best val acc: 0.9562\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 모델 평가"
      ],
      "metadata": {
        "id": "kFhOlPpnoNrf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 베이스라인 모델 평가를 위한 전처리"
      ],
      "metadata": {
        "id": "Aq-FQ7QorFYo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transform_base = transforms.Compose([transforms.Resize([64, 64]),\n",
        "                                     transforms.ToTensor()])\n",
        "test_base = ImageFolder(root='./splitted/test',\n",
        "                        transform=transform_base)\n",
        "test_loader_base = torch.utils.data.DataLoader(test_base,\n",
        "                      batch_size=batch_size, shuffle=True,\n",
        "                                               num_workers=2)"
      ],
      "metadata": {
        "id": "pvxZRIiLpneI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Transfer Learning 모델 평가를 위한 전처리"
      ],
      "metadata": {
        "id": "yheMXSwxrZsh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transform_resNet = transforms.Compose([\n",
        "    transforms.Resize([64, 64]),\n",
        "    transforms.RandomCrop(52),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "test_resNet = ImageFolder(root='./splitted/test', transform=transform_resNet)\n",
        "test_loader_resNet = torch.utils.data.DataLoader(test_resNet, batch_size=batch_size,\n",
        "                                                 shuffle=True, num_workers=2)"
      ],
      "metadata": {
        "id": "agbh8Q16rcU_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 베이스라인 모델 성능 평가하기"
      ],
      "metadata": {
        "id": "KfIexhUTr27M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "baseline = torch.load('baseline.pt')\n",
        "baseline.eval()\n",
        "test_loss, test_accuracy = evaluate(baseline, test_loader_base)\n",
        "print(test_accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O4nntVZbsysu",
        "outputId": "5231d81a-0820-40e4-e6c3-26723dacd64d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(94.1044, device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Transfer Learning 모델 성능 평가하기"
      ],
      "metadata": {
        "id": "Jm2m-iCBs-zD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "resnet50 = torch.load('resnet50.pt')\n",
        "resnet50.eval()\n",
        "test_loss, test_accuracy = evaluate(resnet50, test_loader_resNet)\n",
        "print(test_accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HUNyeY3ws9_Y",
        "outputId": "854dd5a2-8ab6-49cc-c38b-f25dd2582989"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(95.8818, device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Transfer Learning의 장점**\n",
        "\n",
        "* 대량의 데이터로 사전 학습한 모델을 사용하는 만큼, 더 높은 예측 성능을 보인다. (내가 고생하기 싫어서 에폭을 3으로만 설정해서 그렇지, 값을 바꾸면 아마 성능 격차가 더 커질 거다)\n",
        "* 모델 훈련 속도가 더 빠르다. (**아주 큰 장점이다**)\n",
        "* 이미지 분류 외 영상, 자연어 처리 등 다양한 분야에 사용될 수 있다."
      ],
      "metadata": {
        "id": "EFjQhOiBunJN"
      }
    }
  ]
}